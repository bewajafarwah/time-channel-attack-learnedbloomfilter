{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe69fb34-bc80-424c-a516-21c54aac20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799aff5a-e83f-4a84-b70d-650434b57a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1114187\n",
       "1     779054\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/Japan_dataset_octet_3.csv')\n",
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307f1dcb-341b-42eb-8f38-7a156b0a3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = [int(x) for x in \"{:024b}\".format(self.X[idx])]\n",
    "        y = self.Y[idx]\n",
    "\n",
    "        return torch.tensor(x).float(), torch.tensor([y]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30459b8-aa89-4fbe-992d-ae82e5e1c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.integer.to_numpy()\n",
    "Y = dataset.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537e17ba-302f-44a6-8ddd-ef8b53f981f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_dataset = Dataset(X, Y)\n",
    "dataloader = torch.utils.data.DataLoader(ip_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef096c9e-a052-421a-bc38-fc2a54cfca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=24, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_in = 24\n",
    "model_arch = [model_in, 256, 128, 64, 32]\n",
    "model_out = 1\n",
    "\n",
    "model = torch.nn.Sequential()\n",
    "for i in range(1, len(model_arch)):\n",
    "    model.append(torch.nn.Linear(model_arch[i - 1], model_arch[i]))\n",
    "    model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Linear(model_arch[-1], model_out))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5f33a88-8423-43e5-acd5-731497645c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738bb607-48ab-468e-9d69-81a4aa5cedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(step):\n",
    "   \n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % step == (step - 1):\n",
    "            last_loss = running_loss / step\n",
    "            print(f'batch: {i + 1} | loss: {last_loss}')\n",
    "            running_loss = 0.\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "def _metrics(tn, fp, fn, tp):\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    return accuracy, recall, precision\n",
    "\n",
    "def get_model_metrics(thresh=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = []\n",
    "    tp = tn = fp = fn = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs, labels\n",
    "            \n",
    "            logits = model(inputs)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > thresh).int()\n",
    "            _tn, _fp, _fn, _tp = confusion_matrix(labels, preds).ravel()\n",
    "\n",
    "            tn += _tn\n",
    "            fp += _fp\n",
    "            fn += _fn\n",
    "            tp += _tp\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            running_loss.append(loss.item())\n",
    "            \n",
    "    avg_vloss = np.mean(running_loss)\n",
    "    accuracy, recall, precision = _metrics(tn, fp, fn, tp)\n",
    "    print(tn, fp, fn, tp)\n",
    "    return avg_vloss, accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd6dd0-ff7a-415c-a50b-b843f845bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1\n",
      "batch: 200 | loss: 0.02045377715257928\n",
      "batch: 400 | loss: 0.019379164224956183\n",
      "batch: 600 | loss: 0.019086903231218456\n",
      "batch: 800 | loss: 0.018537037721835077\n",
      "batch: 1000 | loss: 0.01852941380115226\n",
      "batch: 1200 | loss: 0.01875365401385352\n",
      "batch: 1400 | loss: 0.018552384825889022\n",
      "batch: 1600 | loss: 0.018250142452307046\n",
      "batch: 1800 | loss: 0.01820269276155159\n",
      "1109295 4892 6418 772636\n",
      "Acc 0.9940 | Precision 0.9937 | Recall 0.9918\n",
      "\n",
      "EPOCH : 2\n",
      "batch: 200 | loss: 0.018145487850997597\n",
      "batch: 400 | loss: 0.017956386196892708\n",
      "batch: 600 | loss: 0.017283236572984605\n",
      "batch: 800 | loss: 0.01796381570631638\n",
      "batch: 1000 | loss: 0.016818508156575263\n",
      "batch: 1200 | loss: 0.01737298485590145\n",
      "batch: 1400 | loss: 0.017333653066307308\n",
      "batch: 1600 | loss: 0.017309259574394675\n",
      "batch: 1800 | loss: 0.017254087077453732\n",
      "1109579 4608 6213 772841\n",
      "Acc 0.9943 | Precision 0.9941 | Recall 0.9920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#20 EPOCHS ALREADY DONE.\n",
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH : {epoch + 1}')\n",
    "    \n",
    "    avg_tloss = train_one_epoch(step=200)\n",
    "    avg_vloss, accuracy, recall, precision = get_model_metrics()\n",
    "    \n",
    "    print(f'Acc {accuracy:.4f} | Precision {precision:.4f} | Recall {recall:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c6e055-aab0-4028-ad0f-e498fa80c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"saved_model/Japan_256_128_64_32_fp_4608_later.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
